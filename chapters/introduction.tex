\section{Thesis structure}

This thesis follows the structure below in the upcoming chapers:
\begin{itemize}
    \item Chapter 2 includes all the necessary technical background and notation to understand the succeeding chapters 2.  
    \item Chapter 3 introduces a method for hierarchical Linearly-solvable markov decision processes. This work was published under the name of \textit{``Globally optimal hierarchical reinforcement learning for linearly-solvable markov decision processes''} in the Proceedings of the 36th AAAI Conference on Artificial Intelligence in 2022.
    \item Chapter 3 follows up the previous work and extends the method for the average-reward setting. This work was recently accepted for publication as \textit{``Hierarchical Average-Reward Linearly-solvable Markov Decision Processes''} in the 27th European COnference on Artificial Intelligence.
    \item In Chapter 4, a framework to exploit compositionality for solving complex task in a more general reinforcement learning setting is presented. Part of this work was published as a paper and presented at the 37th of the International Conference on Automated Planning and Scheduling. The paper is \textit{``Planning with a Learned Policy Basis to Optimally Solve Complex Tasks''} and is the product of a four months research stay at the University of Amsterdam, under the supervision of Herke van Hoof.
    \item Lastly, in Chapter 5 the final remarks and conclusions of the thesis are discussed as well as some possible lines of future work.
\end{itemize}

\section{Contributions}